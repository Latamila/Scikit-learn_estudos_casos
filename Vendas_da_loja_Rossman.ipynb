{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjLldMJYV4gDQP9j0k3X+/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Latamila/Scikit-learn_estudos_casos/blob/main/Vendas_da_loja_Rossman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DESCRIÇÃO\n",
        "---\n",
        "Rossmann opera mais de 3.000 drogarias em 7 países europeus. Atualmente, os gerentes das lojas Rossmann têm a tarefa de prever suas vendas diárias com até seis semanas de antecedência. As vendas nas lojas são influenciadas por muitos fatores, incluindo promoções, concorrência, feriados escolares e estaduais, sazonalidade e localidade. Com milhares de gestores individuais prevendo vendas com base em circunstâncias específicas, a precisão dos resultados pode ser bastante variada.\n",
        "\n",
        "Em sua primeira competição Kaggle, Rossmann desafia você a prever 6 semanas de vendas diárias para 1.115 lojas localizadas em toda a Alemanha. Previsões de vendas confiáveis ​​permitem que os gerentes de loja criem cronogramas de equipe eficazes que aumentam a produtividade e a motivação. Ao ajudar a Rossmann a criar um modelo de previsão robusto, você ajudará os gerentes de loja a manterem o foco no que é mais importante para eles: seus clientes e suas equipes!\n",
        "\n"
      ],
      "metadata": {
        "id": "z5-T-Khd2Kja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Id - um Id que representa um duple (Loja, Data) dentro do conjunto de teste\n",
        "- Loja – um ID exclusivo para cada loja\n",
        "Vendas - o faturamento de um determinado dia (é isso que você está prevendo)\n",
        "- Clientes - o número de clientes em um determinado dia\n",
        "- Aberta - um indicador para saber se a loja estava aberta: 0 = fechada, 1 = aberta\n",
        "- StateHoliday – indica feriado estadual. Normalmente todas as lojas, com poucas exceções, fecham nos feriados estaduais. Observe que todas as escolas estão fechadas nos feriados e fins de semana. a = feriado, b = feriado de Páscoa, c = Natal, 0 = Nenhum\n",
        "- SchoolHoliday - indica se a (Loja, Data) foi afetada pelo fechamento de escolas públicas\n",
        "- StoreType  - diferencia entre 4 modelos de loja diferentes: a, b, c, d\n",
        "Sortimento - descreve um nível de sortimento: a = básico, b = extra, c = estendido\n",
        "- CompetitionDistance - distância em metros até a loja concorrente mais próxima\n",
        "- CompetitionOpenSince[Month/Year] - fornece o ano e mês aproximados da hora em que o concorrente mais próximo foi aberto\n",
        "- Promoção - indica se uma loja está realizando uma promoção naquele dia\n",
        "- Promo2 - Promo2 é uma promoção contínua e consecutiva para algumas lojas: 0 = loja não participa, 1 = loja participa\n",
        "- Promo2Since[Ano/Semana] - descreve o ano e a semana do calendário em que a loja começou a participar da Promo2\n",
        "- PromoInterval - descreve os intervalos consecutivos de início da Promo2, nomeando os meses em que a promoção é reiniciada. Por exemplo, \"fevereiro, maio, agosto, novembro\" significa que cada rodada começa em fevereiro, maio, agosto e novembro de qualquer ano para aquela loja"
      ],
      "metadata": {
        "id": "HXPyYxl2kkWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "SoC-TdL9j_8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "VJmG0WfvoiZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "3nhcr8IKonFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "c7k_Sq_WnXiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df_store = pd.read_csv('store.csv')"
      ],
      "metadata": {
        "id": "L6srNOYgngUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the Dataset:\",df_store.shape)"
      ],
      "metadata": {
        "id": "u6RrHjbgnmJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "lg24AWK2nq89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the Dataset:\",df.shape)"
      ],
      "metadata": {
        "id": "dOFGtYLRqoD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "DG7n03eCqyIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_store.head(5)"
      ],
      "metadata": {
        "id": "qmcPRPj1q402"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = df.merge(df_store, on=['Store'], how='inner')\n",
        "print(df_new.shape)"
      ],
      "metadata": {
        "id": "EBe_Uq20rVET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- numero distinto de lojas unicas\n",
        "- numero unicos de dias\n",
        "- media de vendas diarias de todas as lojas"
      ],
      "metadata": {
        "id": "dnZl7YwlsHzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distinct number of Stores :\", len(df_new[\"Store\"].unique()))\n",
        "print(\"Distinct number of Days :\", len(df_new[\"Date\"].unique()))\n",
        "print(\"Average daily sales of all stores : \",round(df_new[\"Sales\"].mean(),2))"
      ],
      "metadata": {
        "id": "jGyAveDZrruW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.dtypes #tipos de dados"
      ],
      "metadata": {
        "id": "ZX7Cm5prr4Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new[\"DayOfWeek\"].value_counts()"
      ],
      "metadata": {
        "id": "QJkfpxHIsAC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ENGENHARIA DE ATRIBUTOS\n",
        "---"
      ],
      "metadata": {
        "id": "Pjf0v5JesfuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new['Date'] = pd.to_datetime(df_new['Date'], infer_datetime_format=True)\n",
        "df_new['Month'] = df_new['Date'].dt.month\n",
        "df_new['Quarter'] = df_new['Date'].dt.quarter\n",
        "df_new['Year'] = df_new['Date'].dt.year\n",
        "df_new['Day'] = df_new['Date'].dt.day\n",
        "df_new['Week'] = df_new['Date'].dt.week\n"
      ],
      "metadata": {
        "id": "ymXuzix6sVtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.head(5)"
      ],
      "metadata": {
        "id": "VN8HfbORtKS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new['Season'] = np.where(df_new['Month'].isin([3,4,5]),\n",
        "                            'Spring',\n",
        "                            np.where(df_new['Month'].isin([6,7,8]),\n",
        "                                     'Summer',\n",
        "                                     np.where(df_new['Month'].isin([9,10,11]),\n",
        "                                              'Fall',\n",
        "                                              np.where(df_new['Month'].isin([12,1,2]),\n",
        "                                                       'Winter', 'None'))))"
      ],
      "metadata": {
        "id": "9N1zjqJ-tQSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando o comando `head` para ver apenas os dados e as features feitas na engenharia de atributos"
      ],
      "metadata": {
        "id": "AI39pIQtuow-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_new[['Date','Year','Month','Day','Week',\n",
        "              'Quarter','Season']].head())"
      ],
      "metadata": {
        "id": "g9Z0kPzmu4ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VISUALIZAÇÃO DOS DADOS\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JXY3aa1avMgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a histogram to study the Daily Sales for the stores\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.grid()\n",
        "plt.hist(df_new[\"Sales\"])\n",
        "plt.title(\"Histogram for Store Sales\")\n",
        "plt.xlabel(\"bins\")\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BX72l71ivVNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.grid()\n",
        "sns.kdeplot(df_new[\"Sales\"], fill=True)\n",
        "plt.title(\"Histogram for Store Sales\")\n",
        "plt.xlabel(\"bins\")\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bgzY19YivW3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explorando Colunas Numericas\n",
        "---\n"
      ],
      "metadata": {
        "id": "NwbEGZ3hvbQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.hist(figsize=(20,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XnOSUfnhvuIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dados faltantes\n",
        "---"
      ],
      "metadata": {
        "id": "bq9-kh5gv26-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df_new.columns:\n",
        "    print('Valores faltantes em', i, 'é -', ' ', df_new[i].isnull().sum()/df_new.shape[0]*100)"
      ],
      "metadata": {
        "id": "G1bFLHSfv__M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imputação com Mode Values\n",
        "---"
      ],
      "metadata": {
        "id": "d5xJhif3wWkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new['CompetitionDistance'] = df_new['CompetitionDistance'].fillna(df_new['CompetitionDistance'].mode()[0])"
      ],
      "metadata": {
        "id": "9Yc4p8EownEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checagem dupla se ainda vemos valores nulos para a coluna\n",
        "---"
      ],
      "metadata": {
        "id": "X3jzBj5lw8Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new[\"CompetitionDistance\"].isnull().sum()/df_new.shape[0] * 100"
      ],
      "metadata": {
        "id": "4rfeqwBexGSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entendendo as variáveis categóricas\n",
        "---"
      ],
      "metadata": {
        "id": "BD0MrnCJxJXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the bar plot for Average Sales across different Seasons\n",
        "ax = sns.barplot(x=\"Season\", y=\"Sales\", data=df_new)"
      ],
      "metadata": {
        "id": "1qLUuc_BxP3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the bar plot for Average Sales across different Assortments\n",
        "ax = sns.barplot(x=\"Assortment\", y=\"Sales\", data=df_new)"
      ],
      "metadata": {
        "id": "hLKfu92_xTUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the bar plot for Average Sales across different Store Types\n",
        "ax = sns.barplot(x=\"StoreType\", y=\"Sales\", data=df_new)"
      ],
      "metadata": {
        "id": "nVR0BILHxi_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.barplot(x=\"Season\", y=\"Sales\", data=df_new,estimator=np.size)"
      ],
      "metadata": {
        "id": "GKEC-4U0xukS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.barplot(x=\"Assortment\", y=\"Sales\", data=df_new,estimator=np.size)"
      ],
      "metadata": {
        "id": "UYSKSxFSx26k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.barplot(x=\"StoreType\", y=\"Sales\", data=df_new,estimator=np.size)"
      ],
      "metadata": {
        "id": "EAGbTYsWx_xS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ENGENHARIA DE DADOS\n",
        "---\n",
        "Defina uma variável para cada tipo de feature(caracteristica)"
      ],
      "metadata": {
        "id": "_WJLufCUyIxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "4d99GlQEybwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['Sales']"
      ],
      "metadata": {
        "id": "F4dxif06ynZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = [\"Customers\",\"Open\",\"Promo\",\"Promo2\",\"StateHoliday\",\"SchoolHoliday\",\n",
        "                   \"CompetitionDistance\"]\n",
        "categorical_columns = [\"DayOfWeek\",\"Quarter\",\"Month\",\"Year\",\n",
        "                       \"StoreType\",\"Assortment\",\"Season\"]"
      ],
      "metadata": {
        "id": "Tdq74ZMuysOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defina uma função que irá consumir o dataframe bruto\n",
        "def create_ohe(df, col):\n",
        "    le = LabelEncoder()\n",
        "    a=le.fit_transform(df_new[col]).reshape(-1,1)\n",
        "    ohe = OneHotEncoder(sparse=False)\n",
        "    column_names = [col+ \"_\"+ str(i) for i in le.classes_]\n",
        "    return(pd.DataFrame(ohe.fit_transform(a),columns =column_names))"
      ],
      "metadata": {
        "id": "kgYs0jmuywTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Como a função acima converte a coluna, uma de cada vez\n",
        "#Criamos um loop para criar o conjunto de dados final com todos os recursos\n",
        "temp = df_new[numeric_columns]\n",
        "for column in categorical_columns:\n",
        "    temp_df = create_ohe(df_new, column)\n",
        "    temp = pd.concat([temp, temp_df], axis=1)"
      ],
      "metadata": {
        "id": "VPrk8_hKzBMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of Data:\",temp.shape)\n",
        "print(\"Distinct Datatypes:\",temp.dtypes.unique())"
      ],
      "metadata": {
        "id": "8l-dpSaSzsi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(temp.columns[temp.dtypes==\"object\"])"
      ],
      "metadata": {
        "id": "XezRBtv6zxTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp[\"StateHoliday\"].unique()"
      ],
      "metadata": {
        "id": "l8l9UBolz3AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp[\"StateHoliday\"]= np.where(temp[\"StateHoliday\"]== '0',0,1)\n",
        "#One last check of the data type\n",
        "temp.dtypes.unique()"
      ],
      "metadata": {
        "id": "ctZinne5z8Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp['StateHoliday']"
      ],
      "metadata": {
        "id": "mtbbLp0M0H13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train-test\n",
        "---"
      ],
      "metadata": {
        "id": "u_7TsH5V0PZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "XUfmTLSM0etd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(temp,df_new[target],test_size=0.2,random_state=2018)"
      ],
      "metadata": {
        "id": "vWUclQY00jIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divida ainda mais o conjunto de dados de treinamento em conjunto de dados de treinamento e validação com uma divisão 90:10\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,test_size=0.1,random_state=2018)"
      ],
      "metadata": {
        "id": "9ZMueAea0mYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the sizes of all newly created datasets\n",
        "print(\"Shape of x_train:\",x_train.shape)\n",
        "print(\"Shape of x_val:\",x_val.shape)\n",
        "print(\"Shape of x_test:\",x_test.shape)\n",
        "print(\"Shape of y_train:\",y_train.shape)\n",
        "print(\"Shape of y_val:\",y_val.shape)\n",
        "print(\"Shape of y_test:\",y_test.shape)"
      ],
      "metadata": {
        "id": "poe1V-lW0_vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Definição do desempenho da linha de base do modelo\n",
        "---"
      ],
      "metadata": {
        "id": "cFUHA66C1GZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CALCULA a média do conjunto de treino\n",
        "mean_sales = y_train.mean()\n",
        "print('Média de Vendas: ', mean_sales)"
      ],
      "metadata": {
        "id": "bmGSUATd122e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcula o erro medio absoluto do conjunto de teste\n",
        "print('MAE para Dados De Teste: ', abs(y_test - mean_sales).mean()[0])"
      ],
      "metadata": {
        "id": "n29uCWI92tVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Projetando a DNN\n",
        "---\n",
        "- Comece com arquiteturas pequenas.\n",
        "- Quando arquiteturas pequenas (com duas camadas) falharem, aumente o tamanho.\n",
        "- Quando redes maiores com duas camadas falharem, vá mais fundo.\n",
        "- Quando redes maiores e mais profundas também falharem, vá ainda maior e mais fundo.\n",
        "- Quando tudo falhar, revise os dados"
      ],
      "metadata": {
        "id": "tP60_XwS3qRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Deep Neural Network Architecture\n",
        "---"
      ],
      "metadata": {
        "id": "NbR0peu_3JVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "40WwMPqD4Ox-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(150, input_dim = 44, activation='relu'))"
      ],
      "metadata": {
        "id": "4OcXonmb4a-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#O input_dim =44, já que a largura dos dados de treinamento=44 (consulte a seção de engenharia de dados)\n",
        "model.add(Dense(1, activation = 'linear'))"
      ],
      "metadata": {
        "id": "I_NPaOgg4teb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configurar o modelo\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error',metrics=['mean_absolute_error'])"
      ],
      "metadata": {
        "id": "nBvTHF_I42mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#treinar o modelo\n",
        "model.fit(x_train.values, y_train.values, validation_data=(x_val,y_val),epochs=10,batch_size=64)"
      ],
      "metadata": {
        "id": "CR9prWkT5G5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Testando a performance do modelo\n",
        "---"
      ],
      "metadata": {
        "id": "cZvc0MVB5XML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use o método de avaliação do modelo para prever\n",
        "#e avaliar os conjuntos de dados de teste\n",
        "result = model.evaluate(x_test.values, y_test.values)\n",
        "\n",
        "#printa os resultados\n",
        "for i in range(len(model.metrics_names)):\n",
        "    print('Metric', model.metrics_names[i],':', str(round(result[i], 2)))"
      ],
      "metadata": {
        "id": "ZMMyM5DN5kAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Melhorando o modelo\n",
        "---\n",
        "Na rede a seguir, adicionamos mais duas camadas com números semelhantes de neurônios. Atualizaremos nossa função de perda para erro quadrático médio em vez de MAE"
      ],
      "metadata": {
        "id": "g5sw3A6W6Yql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(150, input_dim=44, activation='relu'))\n",
        "model.add(Dense(150, activation='relu'))\n",
        "model.add(Dense(150, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val,y_val),epochs=10, batch_size=64)\n",
        "#result = model.evaluate(x_test, y_test)\n",
        "\n",
        "for i in range(len(model.metrics_names)):\n",
        "    print('Metrica ', model.metrics_names[i],':', str(round(result[i], 2)))"
      ],
      "metadata": {
        "id": "b80yJzqM6dGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(150,input_dim = 44,activation=\"relu\"))\n",
        "model.add(Dense(150,activation=\"relu\"))\n",
        "model.add(Dense(150,activation=\"relu\"))\n",
        "model.add(Dense(150,activation=\"relu\"))\n",
        "model.add(Dense(150,activation=\"relu\"))\n",
        "model.add(Dense(1,activation = \"linear\"))\n",
        "model.compile(optimizer='adam',loss=\"mean_squared_error\",metrics=[\"mean_absolute_error\"])\n",
        "model.fit(x_train,y_train, validation_data=(x_val,y_val),\n",
        "epochs=15,batch_size=64)\n",
        "result = model.evaluate(x_test,y_test)\n",
        "for i in range(len(model.metrics_names)):\n",
        "    print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))"
      ],
      "metadata": {
        "id": "Af57D6ej8HHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aumentando o número de neurônios\n",
        "\n",
        "- duas camadas ocultas com 350 neurônios cada e usam uma configuração de modelo\n",
        "\n",
        "- 15 epocas"
      ],
      "metadata": {
        "id": "kXHv6dqfZR9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(350,input_dim = 44,activation=\"relu\"))\n",
        "model.add(Dense(350,activation=\"relu\"))\n",
        "model.add(Dense(1,activation = \"linear\"))\n",
        "model.compile(optimizer='adam',loss=\"mean_squared_error\",metrics=[\"mean_absolute_error\"])\n",
        "model.fit(x_train,y_train, validation_data=(x_val,y_val),\n",
        "epochs=15,batch_size=64)\n",
        "result = model.evaluate(x_test,y_test)\n",
        "for i in range(len(model.metrics_names)):\n",
        "    print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-XB-MA8ZSup",
        "outputId": "fccc7e8c-cac7-4040-e2cb-1b3300af8cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "11444/11444 [==============================] - 43s 4ms/step - loss: 1674571.5000 - mean_absolute_error: 845.3023 - val_loss: 1203456.3750 - val_mean_absolute_error: 739.9495\n",
            "Epoch 2/15\n",
            "11444/11444 [==============================] - 38s 3ms/step - loss: 1162637.2500 - mean_absolute_error: 727.5677 - val_loss: 1081292.6250 - val_mean_absolute_error: 694.7469\n",
            "Epoch 3/15\n",
            "11444/11444 [==============================] - 38s 3ms/step - loss: 1090188.7500 - mean_absolute_error: 702.7058 - val_loss: 1016140.6875 - val_mean_absolute_error: 674.0535\n",
            "Epoch 4/15\n",
            "11444/11444 [==============================] - 38s 3ms/step - loss: 1050317.2500 - mean_absolute_error: 688.6359 - val_loss: 1127280.5000 - val_mean_absolute_error: 741.4191\n",
            "Epoch 5/15\n",
            "11444/11444 [==============================] - 38s 3ms/step - loss: 1024984.7500 - mean_absolute_error: 680.3226 - val_loss: 1001159.6250 - val_mean_absolute_error: 680.5441\n",
            "Epoch 6/15\n",
            "11444/11444 [==============================] - 37s 3ms/step - loss: 1008243.3125 - mean_absolute_error: 674.6683 - val_loss: 969169.1875 - val_mean_absolute_error: 671.4595\n",
            "Epoch 7/15\n",
            "11444/11444 [==============================] - 37s 3ms/step - loss: 989595.3750 - mean_absolute_error: 669.0439 - val_loss: 937595.0625 - val_mean_absolute_error: 656.3386\n",
            "Epoch 8/15\n",
            "11444/11444 [==============================] - 38s 3ms/step - loss: 974688.6250 - mean_absolute_error: 664.2857 - val_loss: 924801.6875 - val_mean_absolute_error: 648.3356\n",
            "Epoch 9/15\n",
            "11444/11444 [==============================] - 39s 3ms/step - loss: 958990.2500 - mean_absolute_error: 659.7241 - val_loss: 973764.1875 - val_mean_absolute_error: 673.5953\n",
            "Epoch 10/15\n",
            "11444/11444 [==============================] - 39s 3ms/step - loss: 946628.0000 - mean_absolute_error: 655.8602 - val_loss: 938795.1250 - val_mean_absolute_error: 655.4448\n",
            "Epoch 11/15\n",
            "11444/11444 [==============================] - 40s 3ms/step - loss: 933665.4375 - mean_absolute_error: 652.0607 - val_loss: 890635.0000 - val_mean_absolute_error: 642.2245\n",
            "Epoch 12/15\n",
            "11444/11444 [==============================] - 43s 4ms/step - loss: 920746.5625 - mean_absolute_error: 647.9564 - val_loss: 932374.0625 - val_mean_absolute_error: 662.2939\n",
            "Epoch 13/15\n",
            "11444/11444 [==============================] - 39s 3ms/step - loss: 914708.5625 - mean_absolute_error: 645.8446 - val_loss: 907005.0000 - val_mean_absolute_error: 654.3500\n",
            "Epoch 14/15\n",
            "11444/11444 [==============================] - 39s 3ms/step - loss: 898813.5625 - mean_absolute_error: 640.8102 - val_loss: 959720.7500 - val_mean_absolute_error: 676.9698\n",
            "Epoch 15/15\n",
            "11444/11444 [==============================] - 39s 3ms/step - loss: 891665.8125 - mean_absolute_error: 638.1350 - val_loss: 836006.5000 - val_mean_absolute_error: 623.6599\n",
            "6358/6358 [==============================] - 15s 2ms/step - loss: 840316.4375 - mean_absolute_error: 622.2335\n",
            "Metric  loss : 840316.44\n",
            "Metric  mean_absolute_error : 622.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusão\n",
        "\n",
        "Podemos ver algumas melhorias quando usamos uma arquitetura que foi construída com um número maior de neurônios. Podemos usar o histórico, pós-treinamento, para visualizar e entender a curva de aprendizado do modelo."
      ],
      "metadata": {
        "id": "h6bUI5TnaRBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import History\n",
        "history = History()\n",
        "model = Sequential()\n",
        "model.add(Dense(350,input_dim = 44,activation=\"relu\"))\n",
        "model.add(Dense(350,activation=\"relu\"))\n",
        "model.add(Dense(350,activation=\"relu\"))\n",
        "model.add(Dense(350,activation=\"relu\"))\n",
        "model.add(Dense(350,activation=\"relu\"))\n",
        "model.add(Dense(1,activation = \"linear\"))\n",
        "model.compile(optimizer='adam',loss=\"mean_squared_error\",metrics=[\"mean_absolute_error\"])\n",
        "model.fit(x_train,y_train, validation_data=(x_val,y_val),\n",
        "epochs=15,batch_size=64,callbacks=[history])\n",
        "result = model.evaluate(x_test,y_test)\n",
        "\n",
        "for i in range(len(model.metrics_names)):\n",
        "    print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))"
      ],
      "metadata": {
        "id": "RKq_sDP1aX8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba34472-d220-4775-e1c4-051568396cf2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "11444/11444 [==============================] - 54s 4ms/step - loss: 1618486.0000 - mean_absolute_error: 837.5728 - val_loss: 1259849.8750 - val_mean_absolute_error: 738.6974\n",
            "Epoch 2/15\n",
            "11444/11444 [==============================] - 51s 4ms/step - loss: 1177575.6250 - mean_absolute_error: 726.6656 - val_loss: 1294894.6250 - val_mean_absolute_error: 732.8755\n",
            "Epoch 3/15\n",
            "11444/11444 [==============================] - 51s 4ms/step - loss: 1106218.0000 - mean_absolute_error: 703.5497 - val_loss: 1058466.0000 - val_mean_absolute_error: 693.3434\n",
            "Epoch 4/15\n",
            "11444/11444 [==============================] - 55s 5ms/step - loss: 1063446.5000 - mean_absolute_error: 689.9120 - val_loss: 1031878.9375 - val_mean_absolute_error: 688.3062\n",
            "Epoch 5/15\n",
            "11444/11444 [==============================] - 49s 4ms/step - loss: 1040647.3125 - mean_absolute_error: 683.1877 - val_loss: 1014320.7500 - val_mean_absolute_error: 676.1426\n",
            "Epoch 6/15\n",
            "11444/11444 [==============================] - 49s 4ms/step - loss: 1013432.9375 - mean_absolute_error: 674.9365 - val_loss: 1018483.9375 - val_mean_absolute_error: 671.7645\n",
            "Epoch 7/15\n",
            "11444/11444 [==============================] - 49s 4ms/step - loss: 1002608.2500 - mean_absolute_error: 671.9153 - val_loss: 936734.5625 - val_mean_absolute_error: 658.0815\n",
            "Epoch 8/15\n",
            "11444/11444 [==============================] - 49s 4ms/step - loss: 980410.3125 - mean_absolute_error: 664.5693 - val_loss: 903351.6875 - val_mean_absolute_error: 647.0719\n",
            "Epoch 9/15\n",
            "11444/11444 [==============================] - 50s 4ms/step - loss: 962517.1875 - mean_absolute_error: 659.2116 - val_loss: 922765.1875 - val_mean_absolute_error: 643.2701\n",
            "Epoch 10/15\n",
            "11444/11444 [==============================] - 49s 4ms/step - loss: 947995.6875 - mean_absolute_error: 654.2933 - val_loss: 967652.9375 - val_mean_absolute_error: 680.4127\n",
            "Epoch 11/15\n",
            "11444/11444 [==============================] - 50s 4ms/step - loss: 932410.0625 - mean_absolute_error: 649.3383 - val_loss: 967584.3750 - val_mean_absolute_error: 654.6576\n",
            "Epoch 12/15\n",
            "11444/11444 [==============================] - 56s 5ms/step - loss: 920080.1250 - mean_absolute_error: 644.9720 - val_loss: 898900.3750 - val_mean_absolute_error: 647.4282\n",
            "Epoch 13/15\n",
            "11444/11444 [==============================] - 49s 4ms/step - loss: 905639.8125 - mean_absolute_error: 640.4564 - val_loss: 880855.5625 - val_mean_absolute_error: 637.1647\n",
            "Epoch 14/15\n",
            "11444/11444 [==============================] - 49s 4ms/step - loss: 898046.0625 - mean_absolute_error: 636.7895 - val_loss: 839881.3125 - val_mean_absolute_error: 617.7644\n",
            "Epoch 15/15\n",
            "11444/11444 [==============================] - 49s 4ms/step - loss: 888967.0000 - mean_absolute_error: 633.1379 - val_loss: 869745.6250 - val_mean_absolute_error: 628.8082\n",
            "6358/6358 [==============================] - 15s 2ms/step - loss: 876535.3750 - mean_absolute_error: 627.4564\n",
            "Metric  loss : 876535.38\n",
            "Metric  mean_absolute_error : 627.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plotando a Métrica de Perda através das épocas\n",
        "---"
      ],
      "metadata": {
        "id": "Yu6_RtDIapfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testando o Modelo\n",
        "---\n",
        "Prever manualmente a partir do modelo, em vez de usar a função de avaliação do modelo"
      ],
      "metadata": {
        "id": "2JYG_Puiaw3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[\"Prediction\"] = model.predict(x_test)\n",
        "y_test.columns = [\"Actual Sales\",\"Predicted Sales\"]\n",
        "print(y_test.head(10))"
      ],
      "metadata": {
        "id": "6lUHfVXza6jt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09eb34c8-f9d6-4dc5-e30b-331b4a66dea5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6358/6358 [==============================] - 11s 2ms/step\n",
            "        Actual Sales  Predicted Sales\n",
            "115563             0         0.349251\n",
            "832654             0         0.349251\n",
            "769112          2933      3070.576904\n",
            "350588          8602      7443.703125\n",
            "141556          6975      6527.319336\n",
            "84435           9239      8422.892578\n",
            "53018              0         0.349251\n",
            "262419             0         0.349251\n",
            "702267          5885      5171.796387\n",
            "981431             0         0.349251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Manually predicting from the model, instead of using model's evaluate function\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "print(\"MSE :\",mean_squared_error(y_test[\"Actual Sales\"].values,y_test[\"Predicted Sales\"].values))\n",
        "print(\"MAE :\",mean_absolute_error(y_test[\"Actual Sales\"].values,y_test[\"Predicted Sales\"].values))"
      ],
      "metadata": {
        "id": "lvJB6mIpbrMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c22f44-1fc9-4b43-8c3c-14322cbecde0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE : 876537.0571696477\n",
            "MAE : 627.4551643114419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONCLUSÃO\n",
        "---\n",
        "- Começamos com a declaração do problema e a definimos usando estruturas padrão do setor para obter uma compreensão intuitiva de por que estamos resolvendo esse problema.\n",
        "- Em seguida, exploramos os dados para compreender os recursos disponíveis e os diferentes tipos de dados"
      ],
      "metadata": {
        "id": "FrdxGtRi1bXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FIM"
      ],
      "metadata": {
        "id": "xMEGg0Uh2JPo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MYycOUHC2RZl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}